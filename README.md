# Real_time_sign_tranislatation
#REAL TIME LANGUAGE ASSISTANT FOR SIGN TRANSLATION

ABSTRACT
Sign language is one of the oldest
and most natural form of language
for communication, but since most
people do not know sign language
and interpreters are very difficult to
come by, we have come up with a
real time method using neural
networks for fingerspelling based
on American sign language. In our
method, the hand is first passed
through a filter and after the filter is
applied the hand is passed through a
classifier which predicts the class of
the hand gestures.
With the advancements in computer
vision technology, learning and
using sign languages to
communicate with deaf and mute
people has become easier. Exciting
research is ongoing for providing a
global platform for communication
in different sign languages. In this
project, we present a Deep
Learning-based approach to
recognize a sign performed in
American Sign Language by
capturing an image as input. The
system can predict the signs of A to
Z and Hand gestures performed by
the user. By utilizing image
processing to convert RGB data to
grayscale images, an efficient
reduction is achieved in the storage
requirements and training time of
the Convolutional Neural Network.
The objective of the experiment is
to find a mix of Image Processing
and Deep Learning Architecture
with lesser complexity to deploy the
system.
